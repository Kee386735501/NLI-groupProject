{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "LSTM + Pytorch For User Stories Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "1.1 Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import torch\n",
    "\n",
    "\n",
    "#read dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv('training_data/NLI/train.csv')\n",
    "premise_data = df['premise'].tolist()\n",
    "hypothesis_data = df['hypothesis'].tolist()\n",
    "label_data = df['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# data clean\n",
    "paired_data = list(zip(premise_data, hypothesis_data, label_data))\n",
    "\n",
    "duplicates = set()\n",
    "unique_paired_data = []\n",
    "for pair in paired_data:\n",
    "    if (pair in duplicates) or (pair[0] == pair[1]) or len(pair[0]) == 0 or len(pair[1]) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        duplicates.add(pair)\n",
    "        unique_paired_data.append(pair)\n",
    "\n",
    "premise_data, hypothesis_data, label_data = zip(*unique_paired_data)\n",
    "    \n",
    "premise_data_clean_garbled = [re.sub(r'[^a-zA-Z0-9\\s]', '', text) for text in premise_data]\n",
    "hypothesis_data_clean_garbled = [re.sub(r'[^a-zA-Z0-9\\s]', '', text) for text in hypothesis_data]\n",
    "\n",
    "cleaned_premise_data = [' '.join(re.sub(r'\\b\\w*www\\w*\\b', '', text).split()) for text in premise_data_clean_garbled]\n",
    "cleaned_hypothesis_data = [' '.join(re.sub(r'\\b\\w*www\\w*\\b', '', text).split()) for text in hypothesis_data_clean_garbled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "preprocessed_premise_data = [word_tokenize(text) for text in cleaned_premise_data]\n",
    "filtered_premise_data = [[word.lower() for word in premise if word.lower() not in stop_words] for premise in preprocessed_premise_data]\n",
    "\n",
    "preprocessed_hypothesis_data = [word_tokenize(text) for text in cleaned_hypothesis_data]\n",
    "filtered_hypothesis_data = [[word.lower() for word in hypothesis if word.lower() not in stop_words] for hypothesis in preprocessed_hypothesis_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from tensorflow.keras.layers import Embedding\n",
    "import numpy as np\n",
    "\n",
    "# 加载预训练的 Word2Vec 模型\n",
    "model = Word2Vec(filtered_premise_data+filtered_hypothesis_data, vector_size=300, window=5, min_count=5)\n",
    "word_vectors = model.wv\n",
    "\n",
    "premise_vectors = []\n",
    "for sentence in filtered_premise_data:\n",
    "    sentence_vectors = []\n",
    "    for word in sentence:\n",
    "        if word in model.wv:\n",
    "            sentence_vectors.append(model.wv[word].tolist())\n",
    "        else:\n",
    "            sentence_vectors.append(np.zeros(model.vector_size).tolist())\n",
    "    premise_vectors.append(sentence_vectors)\n",
    "    \n",
    "hypothesis_vectors = []\n",
    "for sentence in filtered_hypothesis_data:\n",
    "    sentence_vectors = []\n",
    "    for word in sentence:\n",
    "        if word in model.wv:\n",
    "            sentence_vectors.append(model.wv[word].tolist())\n",
    "        else:\n",
    "            sentence_vectors.append(np.zeros(model.vector_size).tolist())\n",
    "    hypothesis_vectors.append(sentence_vectors)\n",
    "\n",
    "\n",
    "# # 应用词向量到 embedding 层\n",
    "# vocab_size = len(word_vectors.key_to_index) + 1\n",
    "# embedding_dim = model.vector_size\n",
    "# embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "# for word, i in word_vectors.key_to_index.items():\n",
    "#     embedding_vector = word_vectors[word]\n",
    "#     if embedding_vector is not None:\n",
    "#         embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"list\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.initializers import Constant\n",
    "# # 创建 embedding 层\n",
    "# embedding_layer = Embedding(vocab_size, embedding_dim, embeddings_initializer=Constant(embedding_matrix), trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen1 = np.max([len(text) for text in filtered_premise_data])\n",
    "maxlen2 = np.max([len(text) for text in filtered_hypothesis_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 128)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_17\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_17\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">     Param # </span>┃<span style=\"font-weight: bold\"> Connected to                   </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_108 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ input_layer_109 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ bidirectional_50              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">186,880</span> │ input_layer_108[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)               │                           │             │ input_layer_109[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ global_max_pooling1d_6        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)          │                           │             │                                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ global_max_pooling1d_7        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)          │                           │             │                                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ subtract_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Subtract</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooling1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                               │                           │             │ global_max_pooling1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ multiply_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooling1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                               │                           │             │ global_max_pooling1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ lambda_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ subtract_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ concatenate_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooling1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                               │                           │             │ global_max_pooling1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                               │                           │             │ multiply_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],             │\n",
       "│                               │                           │             │ lambda_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │      <span style=\"color: #00af00; text-decoration-color: #00af00\">16,416</span> │ concatenate_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                 │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────┴────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m    Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_108 (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │           \u001b[38;5;34m0\u001b[0m │ -                              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ input_layer_109 (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │           \u001b[38;5;34m0\u001b[0m │ -                              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ bidirectional_50              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │     \u001b[38;5;34m186,880\u001b[0m │ input_layer_108[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)               │                           │             │ input_layer_109[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ global_max_pooling1d_6        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m0\u001b[0m │ bidirectional_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)          │                           │             │                                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ global_max_pooling1d_7        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m0\u001b[0m │ bidirectional_50[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)          │                           │             │                                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ subtract_15 (\u001b[38;5;33mSubtract\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m0\u001b[0m │ global_max_pooling1d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                               │                           │             │ global_max_pooling1d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ multiply_19 (\u001b[38;5;33mMultiply\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m0\u001b[0m │ global_max_pooling1d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                               │                           │             │ global_max_pooling1d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ lambda_15 (\u001b[38;5;33mLambda\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m0\u001b[0m │ subtract_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ concatenate_11 (\u001b[38;5;33mConcatenate\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)               │           \u001b[38;5;34m0\u001b[0m │ global_max_pooling1d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                               │                           │             │ global_max_pooling1d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                               │                           │             │ multiply_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],             │\n",
       "│                               │                           │             │ lambda_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │      \u001b[38;5;34m16,416\u001b[0m │ concatenate_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────┼────────────────────────────────┤\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │          \u001b[38;5;34m33\u001b[0m │ dense_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                 │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────┴────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">203,329</span> (794.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m203,329\u001b[0m (794.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">203,329</span> (794.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m203,329\u001b[0m (794.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Subtract, Lambda, Multiply, Concatenate, GlobalMaxPooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow.python.keras.backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "input1 = Input(shape=(None,model.vector_size))\n",
    "input2 = Input(shape=(None,model.vector_size))\n",
    "\n",
    "lstm = Bidirectional(LSTM(64, return_sequences=True))\n",
    "\n",
    "# # 使用 LSTM 层处理输入\n",
    "lstm_output1 = lstm(input1)\n",
    "lstm_output2 = lstm(input2)\n",
    "\n",
    "# 沿着时间步骤轴进行最大池化\n",
    "lstm_output1 = GlobalMaxPooling1D()(lstm_output1)\n",
    "lstm_output2 = GlobalMaxPooling1D()(lstm_output2)\n",
    "\n",
    "multiplied_features = Multiply()([lstm_output1, lstm_output2])\n",
    "\n",
    "subtracted_features = Subtract()([lstm_output1, lstm_output2])\n",
    "absolute_difference = Lambda(lambda x: K.abs(x), output_shape=lambda x: x)(subtracted_features)\n",
    "print(absolute_difference.shape)\n",
    "\n",
    "final_feature = Concatenate()([lstm_output1, lstm_output2, multiplied_features, absolute_difference])\n",
    "\n",
    "# 全连接层\n",
    "dense1 = Dense(128, activation='relu')(final_feature)\n",
    "dense1 = Dense(32, activation='relu')(final_feature)\n",
    "dense2 = Dense(1, activation='sigmoid')(dense1)\n",
    "\n",
    "# 创建模型\n",
    "model_NLI = Model(inputs=[input1, input2], outputs=dense2)\n",
    "\n",
    "# 编译模型\n",
    "model_NLI.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 打印模型结构\n",
    "model_NLI.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "validation_size = int(len(premise_vectors) * 0.2)\n",
    "\n",
    "p_val = premise_vectors[-validation_size:]\n",
    "h_val = hypothesis_vectors[-validation_size:]\n",
    "label_val = label_data[-validation_size:]\n",
    "\n",
    "p_train = premise_vectors[:-validation_size]\n",
    "h_train = hypothesis_vectors[:-validation_size]\n",
    "label_train = label_data[:-validation_size]\n",
    "\n",
    "irregular_array = np.array(p_val, dtype=object)\n",
    "padded_p_val = pad_sequences(irregular_array, padding='post', dtype='float32', maxlen=maxlen1)\n",
    "irregular_array = np.array(h_val, dtype=object)\n",
    "padded_h_val = pad_sequences(irregular_array, padding='post', dtype='float32', maxlen=maxlen2)\n",
    "padded_label_val = np.array(label_val)\n",
    "\n",
    "\n",
    "irregular_array = np.array(p_train, dtype=object)\n",
    "padded_p_train = pad_sequences(irregular_array, padding='post', dtype='float32', maxlen=maxlen1)\n",
    "irregular_array = np.array(h_train, dtype=object)\n",
    "padded_h_train = pad_sequences(irregular_array, padding='post', dtype='float32', maxlen=maxlen2)\n",
    "padded_label_train = np.array(label_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padded_label_train = padded_label_train[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padded_label_val = padded_label_val[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 66ms/step - accuracy: 0.5481 - loss: 0.6836 - val_accuracy: 0.5758 - val_loss: 0.6705\n",
      "Epoch 2/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.5895 - loss: 0.6619 - val_accuracy: 0.5915 - val_loss: 0.6604\n",
      "Epoch 3/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.6011 - loss: 0.6538 - val_accuracy: 0.5975 - val_loss: 0.6530\n",
      "Epoch 4/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.6074 - loss: 0.6446 - val_accuracy: 0.6075 - val_loss: 0.6499\n",
      "Epoch 5/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.6190 - loss: 0.6371 - val_accuracy: 0.6165 - val_loss: 0.6440\n",
      "Epoch 6/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.6227 - loss: 0.6310 - val_accuracy: 0.6054 - val_loss: 0.6477\n",
      "Epoch 7/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.6251 - loss: 0.6323 - val_accuracy: 0.6012 - val_loss: 0.6493\n",
      "Epoch 8/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.6393 - loss: 0.6265 - val_accuracy: 0.6249 - val_loss: 0.6434\n",
      "Epoch 9/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.6364 - loss: 0.6248 - val_accuracy: 0.6076 - val_loss: 0.6449\n",
      "Epoch 10/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.6299 - loss: 0.6267 - val_accuracy: 0.6141 - val_loss: 0.6471\n",
      "Epoch 11/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.6451 - loss: 0.6178 - val_accuracy: 0.6174 - val_loss: 0.6485\n",
      "Epoch 12/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.6429 - loss: 0.6178 - val_accuracy: 0.6147 - val_loss: 0.6468\n",
      "Epoch 13/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.6481 - loss: 0.6138 - val_accuracy: 0.6233 - val_loss: 0.6406\n",
      "Epoch 14/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.6559 - loss: 0.6086 - val_accuracy: 0.6209 - val_loss: 0.6416\n",
      "Epoch 15/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.6587 - loss: 0.6072 - val_accuracy: 0.6176 - val_loss: 0.6488\n",
      "Epoch 16/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.6593 - loss: 0.6038 - val_accuracy: 0.6176 - val_loss: 0.6462\n",
      "Epoch 17/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.6621 - loss: 0.6024 - val_accuracy: 0.5999 - val_loss: 0.6606\n",
      "Epoch 18/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.6662 - loss: 0.5998 - val_accuracy: 0.6189 - val_loss: 0.6458\n",
      "Epoch 19/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.6669 - loss: 0.5964 - val_accuracy: 0.6284 - val_loss: 0.6514\n",
      "Epoch 20/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.6814 - loss: 0.5829 - val_accuracy: 0.6194 - val_loss: 0.6498\n",
      "Epoch 21/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.6842 - loss: 0.5824 - val_accuracy: 0.6198 - val_loss: 0.6548\n",
      "Epoch 22/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.6798 - loss: 0.5796 - val_accuracy: 0.6216 - val_loss: 0.6625\n",
      "Epoch 23/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.6915 - loss: 0.5702 - val_accuracy: 0.6115 - val_loss: 0.6657\n",
      "Epoch 24/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - accuracy: 0.7021 - loss: 0.5607 - val_accuracy: 0.6169 - val_loss: 0.6697\n",
      "Epoch 25/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 64ms/step - accuracy: 0.7008 - loss: 0.5564 - val_accuracy: 0.6109 - val_loss: 0.6725\n",
      "Epoch 26/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - accuracy: 0.7082 - loss: 0.5540 - val_accuracy: 0.6101 - val_loss: 0.6728\n",
      "Epoch 27/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - accuracy: 0.7192 - loss: 0.5413 - val_accuracy: 0.6053 - val_loss: 0.6996\n",
      "Epoch 28/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - accuracy: 0.7228 - loss: 0.5361 - val_accuracy: 0.6081 - val_loss: 0.6966\n",
      "Epoch 29/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - accuracy: 0.7277 - loss: 0.5265 - val_accuracy: 0.6133 - val_loss: 0.7033\n",
      "Epoch 30/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - accuracy: 0.7356 - loss: 0.5192 - val_accuracy: 0.6068 - val_loss: 0.7074\n",
      "Epoch 31/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 65ms/step - accuracy: 0.7394 - loss: 0.5141 - val_accuracy: 0.5974 - val_loss: 0.7362\n",
      "Epoch 32/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - accuracy: 0.7444 - loss: 0.5042 - val_accuracy: 0.5965 - val_loss: 0.7165\n",
      "Epoch 33/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - accuracy: 0.7579 - loss: 0.4924 - val_accuracy: 0.6007 - val_loss: 0.7379\n",
      "Epoch 34/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - accuracy: 0.7586 - loss: 0.4859 - val_accuracy: 0.6080 - val_loss: 0.7550\n",
      "Epoch 35/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - accuracy: 0.7684 - loss: 0.4722 - val_accuracy: 0.6055 - val_loss: 0.7653\n",
      "Epoch 36/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.7693 - loss: 0.4715 - val_accuracy: 0.6020 - val_loss: 0.7834\n",
      "Epoch 37/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.7737 - loss: 0.4580 - val_accuracy: 0.5899 - val_loss: 0.8006\n",
      "Epoch 38/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.7826 - loss: 0.4500 - val_accuracy: 0.6018 - val_loss: 0.8060\n",
      "Epoch 39/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.7937 - loss: 0.4313 - val_accuracy: 0.5874 - val_loss: 0.8302\n",
      "Epoch 40/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.8042 - loss: 0.4214 - val_accuracy: 0.5965 - val_loss: 0.8103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x24ebb34dfd0>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_NLI.fit([padded_p_train, padded_h_train], padded_label_train, batch_size=64, epochs=40, validation_data = ([padded_p_val, padded_h_val], padded_label_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 183ms/step - accuracy: 0.6643 - loss: 0.6016 - val_accuracy: 0.6222 - val_loss: 0.6488\n",
      "Epoch 2/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 156ms/step - accuracy: 0.6757 - loss: 0.5898 - val_accuracy: 0.6155 - val_loss: 0.6562\n",
      "Epoch 3/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 161ms/step - accuracy: 0.6751 - loss: 0.5896 - val_accuracy: 0.6135 - val_loss: 0.6520\n",
      "Epoch 4/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 160ms/step - accuracy: 0.6882 - loss: 0.5755 - val_accuracy: 0.6159 - val_loss: 0.6517\n",
      "Epoch 5/40\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 161ms/step - accuracy: 0.6929 - loss: 0.5764 - val_accuracy: 0.6257 - val_loss: 0.6483\n",
      "Epoch 6/40\n",
      "\u001b[1m316/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - accuracy: 0.6972 - loss: 0.5723"
     ]
    }
   ],
   "source": [
    "model_NLI.fit([padded_p_train, padded_h_train], padded_label_train, batch_size=64, epochs=40, validation_data = ([padded_p_val, padded_h_val], padded_label_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
